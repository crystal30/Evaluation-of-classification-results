{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "mydigits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydigits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mydigits.data\n",
    "y = mydigits.target.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：此处不能写成 y = mydigits.target 这样，修改y的值时，也会对mydigits.target 进行修改，因为 y 和 mydigits.target 指向的是同一个引用，为了保证 mydigits.target 不被修改，应用 y=digits.target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[mydigits.target == 9] = 1\n",
    "y[mydigits.target != 9] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note:    \n",
    "y[y == 9] = 1   \n",
    "y[y != 9] = 0   \n",
    "此种写法是错误的, 结果会导致y全部为0,因为 执行y[y == 9] = 1之后， y中的取值为0,1,2,3,4,5,6,7,8 ，即此时取值都不等于9,执行y[y != 9] = 0 之后, y的取值将全为0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用sklearn.linear_model.LogisticRegression 来训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755555555555555"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)\n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(X_train, y_train)\n",
    "logReg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = logReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编写 TN, FP, FN, TP, confusion matrix,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TN(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return sum((y_true == 0) & (y_pred == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FP(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return sum((y_true == 0) & (y_pred == 1))\n",
    "FP(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FN(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return sum((y_true == 1) & (y_pred == 0))\n",
    "FN(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TP(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return sum((y_true == 1) & (y_pred == 1))\n",
    "TP(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[403,   2],\n",
       "       [  9,  36]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return np.array([[TN(y_true, y_pred), FP(y_true, y_pred)],\n",
    "                     [FN(y_true, y_pred), TP(y_true, y_pred)]])\n",
    "\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_score(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    try:\n",
    "        return TP(y_true, y_pred)/(TP(y_true, y_pred) + FP(y_true, y_pred))\n",
    "    except:\n",
    "        return 0\n",
    "precision_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recall_score(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    try:\n",
    "        return TP(y_true, y_pred)/(TP(y_true, y_pred) + FN(y_true, y_pred))\n",
    "    except:\n",
    "        return 0\n",
    "recall_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn中 TN, FP, FN, TP, confusion matrix,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[403,   2],\n",
       "       [  9,  36]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "confusion_matrix(y_test, y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果跟调用我们自己编写的函数的结果一样哟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
